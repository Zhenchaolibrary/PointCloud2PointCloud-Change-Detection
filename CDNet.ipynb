{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch-based Change Detection with Siamese Networks\n",
    "\n",
    "By Zhenchao Zhang (z.zhang-1@utwente.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "All the imports are defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhenchao/CodePyTor\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from random import choice, sample\n",
    "from PIL import Image\n",
    "\n",
    "import PIL.ImageOps \n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import linecache\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "# import cv2\n",
    "\n",
    "#os.chdir('/home/zhangz1/Data/CodeVE/ChangeDetection/')\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhenchao/CodePyTor\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loader(Pos_ids,Neg_ids,linesPos,linesNeg, TrainFlag):  # Loader one batch. Input: 2 lists.   Output: a batch\n",
    "    num = len(Pos_ids)  # should be 128\n",
    "       \n",
    "    for i in range(0,num):\n",
    "        line = linesPos[Pos_ids[i]]\n",
    "        \n",
    "        line.strip('\\n')\n",
    "        img_list= line.split()  # img_list has 4 elements\n",
    "        \n",
    "        img0 = Image.open(cwd+'/Patches/'+img_list[0])  #  ALS, 1 channel, float\n",
    "        img1 = Image.open(cwd+'/Patches/'+img_list[1])  #  DIM, 1 channel, float\n",
    "        img2 = Image.open(cwd+'/Patches/'+img_list[2])  #  Ortho, 3 channels, int [0,255]\n",
    "        \n",
    "        # img0 = img0.resize((112,112), resample=PIL.Image.BICUBIC)\n",
    "        # img1 = img1.resize((112,112), resample=PIL.Image.BICUBIC)\n",
    "        # img2 = img2.resize((112,112), resample=PIL.Image.BICUBIC)\n",
    "        \n",
    "        t = ToTensor()(img0)  # 100*100\n",
    "        t0 = (t-Hmin)/Hdel\n",
    "        t0 = t0.unsqueeze(0)  # unsqueeze to add artificial first dimension\n",
    "        \n",
    "        t = ToTensor()(img1)  # 100*100\n",
    "        t1 = (t-Hmin)/Hdel\n",
    "        t1 = t1.unsqueeze(0)\n",
    "        \n",
    "        t2 = ToTensor()(img2)  # After: 3*100*100\n",
    "        t2 = t2.unsqueeze(0)   # Check if all t0, t1 and t2 are in [0,1]\n",
    "        \n",
    "        label = float(img_list[3])\n",
    "        label = torch.tensor(label)\n",
    "        label = label.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        if i==0:\n",
    "            T0 = t0\n",
    "            T1 = t1\n",
    "            T2 = t2\n",
    "            T3 = label\n",
    "        else:\n",
    "            T0 = torch.cat([T0,t0],0)\n",
    "            T1 = torch.cat([T1,t1],0)\n",
    "            T2 = torch.cat([T2,t2],0)\n",
    "            T3 = torch.cat([T3,label],0)\n",
    "            \n",
    "    batch = [T0, T1, T2, T3]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # [SI-HH-conc-SW]   SI-CNN (HH) (Shared weights)(middle stack fusion)\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        \n",
    "        # Convolution Layer 1      # 1x100x100 input\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=5)  # 3 or 5? \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # after concatenation\n",
    "        self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "        self.conv3 = nn.Conv2d(10, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 9 * 9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)   # 2-D outputs\n",
    "        \n",
    "    def forward(self,X0,X1,X2):\n",
    "        \n",
    "        X0 = self.pool(F.relu(self.conv1(X0)))     # ALS data, 3 chann, 48*48\n",
    "        X1 = self.pool(F.relu(self.conv1(X1)))     # DIM data, 3 chann, 48*48\n",
    "        \n",
    "        x = torch.cat([X0,X1],1)  # size: [64,6,48,48]\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv2(x)))  # size: [64,10,22,22]\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # size: [64,16,9,9]\n",
    "        x = x.view(-1, 16 * 9 * 9)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # [SI-HH-conc-DW] SI-CNN (HH) (UNshared weights)(middle stack fusion)\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "               \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        \n",
    "        # Convolution Layer 1      # 1x100x100 input\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=5)  # 3 or 5? \n",
    "        self.conv1A = nn.Conv2d(1, 3, kernel_size=5)  # 3 or 5? \n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # after concatenation\n",
    "        self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "        self.conv3 = nn.Conv2d(10, 16, 5)\n",
    "             \n",
    "        self.fc1 = nn.Linear(16 * 9 * 9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)   # 2-D outputs\n",
    "        \n",
    "    def forward(self,X0,X1,X2):\n",
    "        \n",
    "        X0 = self.pool(F.relu(self.conv1(X0)))     # ALS data, 3 chann, 48*48\n",
    "        X1 = self.pool(F.relu(self.conv1A(X1)))     # DIM data, 3 chann, 48*48\n",
    "        \n",
    "        x = torch.cat([X0,X1],1)  # size: [64,6,48,48]\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv2(x)))  # size: [64,10,22,22]\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # size: [64,16,9,9]\n",
    "        x = x.view(-1, 16 * 9 * 9)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # [SI-HH-diff-SW]  SI-CNN (HH) (Shared weights)(End abs minus fusion)\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        \n",
    "        # Convolution Layer 1      # 1x100x100 input\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "        self.conv3 = nn.Conv2d(10, 16, 5)\n",
    "        \n",
    "        # after concatenation\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 9 * 9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)   # 2-D outputs\n",
    "        self.fc3 = nn.Linear(84, 2)   # 2-D outputs\n",
    "        \n",
    "    def forward(self,X0,X1,X2):\n",
    "        res = []\n",
    "        \n",
    "        for i in range(2): # Siamese nets; sharing weights\n",
    "            if i==0:\n",
    "                x=X0\n",
    "            if i==1:\n",
    "                x=X1\n",
    "            \n",
    "            x = self.pool(F.relu(self.conv1(x)))     # size: [64,6,48,48]\n",
    "            x = self.pool(F.relu(self.conv2(x)))     # size: [64,10,22,22]\n",
    "            x = self.pool(F.relu(self.conv3(x)))     # size: [64,10,22,22]\n",
    "            \n",
    "            x = x.view(-1, 16 * 9 * 9)    # size: [64,10,22,22]\n",
    "            x = self.fc1(x)     # size: [120*1]\n",
    "            x = F.relu(x)\n",
    "            res.append(x)\n",
    "\n",
    "        res = torch.abs(res[1] - res[0])   # abs|A-B|  # size: [120*1]\n",
    "        res = F.relu(self.fc2(res))\n",
    "        res = self.fc3(res)   # size: [2*1]\n",
    "        return res\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # SI-CNN (HH) (UNshared weights)(End abs minus fusion)\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "               \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        \n",
    "        # Convolution Layer 1      # 1x100x100 input\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)   # 1st branch\n",
    "        self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "        \n",
    "        self.conv1A = nn.Conv2d(1, 6, kernel_size=5)  # 2nd branch\n",
    "        self.conv2A = nn.Conv2d(6, 10, 5)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "           \n",
    "        self.fc1 = nn.Linear(10 * 22 * 22, 120)\n",
    "        self.fc1A = nn.Linear(10 * 22 * 22, 120)\n",
    "        \n",
    "        self.fc2 = nn.Linear(120, 2)   # 2-D outputs\n",
    "        \n",
    "    def forward(self,X0,X1,X2):\n",
    "        res = []\n",
    "        \n",
    "        for i in range(2): # Siamese nets; UNsharing weights\n",
    "            if i==0:\n",
    "                x = X0\n",
    "                x = self.pool(F.relu(self.conv1(x)))     # size: [64,6,48,48]\n",
    "                x = self.pool(F.relu(self.conv2(x)))     # size: [64,10,22,22]\n",
    "                x = x.view(x.shape[0], -1)    # size: [64,10,22,22]\n",
    "                x = self.fc1(x)     # size: [120*1]\n",
    "                x = F.relu(x)\n",
    "                res.append(x)\n",
    "                \n",
    "            if i==1:\n",
    "                x = X1\n",
    "                x = self.pool(F.relu(self.conv1A(x)))     # size: [64,6,48,48]\n",
    "                x = self.pool(F.relu(self.conv2A(x)))     # size: [64,10,22,22]\n",
    "                x = x.view(x.shape[0], -1)    # size: [64,10,22,22]\n",
    "                x = self.fc1A(x)     # size: [120*1]\n",
    "                x = F.relu(x)\n",
    "                res.append(x)\n",
    "\n",
    "        res = torch.abs(res[1] - res[0])   # abs|A-B|  # size: [120*1]\n",
    "        dist = self.fc2(res)   # size: [2*1]\n",
    "        return dist   # size: [2*1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # [SI-HHC-conc-DW][filter=5][NO Batch-Normalization] SI-CNN (HH + color!) (UNshared weights)(middle stack fusion)\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "               \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        \n",
    "        # Convolution Layer 1      # 1x100x100 input\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)  # 3 or 5? \n",
    "        self.conv1A = nn.Conv2d(4, 6, kernel_size=5)  # 3 or 5?\n",
    "               \n",
    "        self.conv2 = nn.Conv2d(6, 10, 5)\n",
    "        self.conv2A = nn.Conv2d(6, 10, 5)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(10, 12, 5)\n",
    "        self.conv3A = nn.Conv2d(10, 12, 5)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # after concatenation\n",
    "        self.conv4 = nn.Conv2d(24, 30, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(30 * 7 * 7, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)   # 2-D outputs\n",
    "        \n",
    "    def forward(self,X0,X1,X2):\n",
    "        \n",
    "        x0 = self.pool(F.relu(self.conv1(X0)))     # ALS data\n",
    "        x0 = self.pool(F.relu(self.conv2(x0)))     # 10*22*22\n",
    "        x0 = F.relu(self.conv3(x0))                # 12*18*18\n",
    "        \n",
    "        x1 = torch.cat([X1,X2],1)  # Concatenate DSM2 and ortho\n",
    "        x1 = self.pool(F.relu(self.conv1A(x1)))     # DIM data\n",
    "        x1 = self.pool(F.relu(self.conv2A(x1)))     # 10*22*22\n",
    "        x1 = F.relu(self.conv3A(x1))                # 12*18*18\n",
    "        \n",
    "        x = torch.cat([x0,x1],1)  # size: [64,24,18,18]\n",
    "        x = self.pool(F.relu(self.conv4(x)))   # [64,30,7,7]\n",
    "        \n",
    "        x = x.view(-1, 30 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # [SI-HHC-conc-DW] [filter=3][8 Conv bocks before] SI-CNN (HH + color!) (UNshared weights)(middle stack fusion)\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        \n",
    "        # Convolution Layer 1      # 1x100x100 input\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,stride=1,padding=1)  # 3 or 5? \n",
    "        self.conv1A = nn.Conv2d(4, 32, kernel_size=3,stride=1,padding=1)  # 3 or 5?\n",
    "                       \n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1, 1)\n",
    "        self.conv2A = nn.Conv2d(32, 32, 3, 1, 1)\n",
    "                \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.conv3A = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        self.conv4A = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.conv5A = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        self.conv6A = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        self.conv7A = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        self.conv8A = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=0)\n",
    "        \n",
    "        # after concatenation\n",
    "        self.conv9 = nn.Conv2d(256, 128, 1, 1, 0)\n",
    "        self.conv10 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2-D outputs\n",
    "        \n",
    "    def forward(self,X0,X1,X2):\n",
    "        # ALS patch\n",
    "        x0 = F.relu(self.conv1(X0))     \n",
    "        x0 = self.pool(F.relu(self.conv2(x0)))\n",
    "        \n",
    "        x0 = F.relu(self.conv3(x0))     \n",
    "        x0 = self.pool(F.relu(self.conv4(x0)))\n",
    "        \n",
    "        x0 = F.relu(self.conv5(x0))     \n",
    "        x0 = self.pool(F.relu(self.conv6(x0)))\n",
    "        \n",
    "        x0 = F.relu(self.conv7(x0))     \n",
    "        x0 = F.relu(self.conv8(x0))\n",
    "        \n",
    "        # DSM2 and ortho               \n",
    "        x1 = torch.cat([X1,X2],1)  # Concatenate \n",
    "        x1 = F.relu(self.conv1A(x1))     \n",
    "        x1 = self.pool(F.relu(self.conv2A(x1)))\n",
    "        \n",
    "        x1 = F.relu(self.conv3A(x1))     \n",
    "        x1 = self.pool(F.relu(self.conv4A(x1)))\n",
    "        \n",
    "        x1 = F.relu(self.conv5A(x1))     \n",
    "        x1 = self.pool(F.relu(self.conv6A(x1)))\n",
    "        \n",
    "        x1 = F.relu(self.conv7A(x1))     \n",
    "        x1 = F.relu(self.conv8A(x1))\n",
    "                \n",
    "        # Concatenate\n",
    "        x = torch.cat([x0,x1],1)  # size: [64,256,14,14]\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = self.pool(F.relu(self.conv10(x)))\n",
    "        \n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # [SI-HHC-conc-DW] [filter==3][4 Conv bocks before] SI-CNN (HH + color!) (UNshared weights)(middle stack fusion)\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        \n",
    "        # Convolution Layer 1      # 1x100x100 input\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,stride=1,padding=1)  # 3 or 5? \n",
    "        self.conv1A = nn.Conv2d(4, 32, kernel_size=3,stride=1,padding=1)  # 3 or 5?\n",
    "                       \n",
    "        #self.conv2 = nn.Conv2d(32, 32, 3, 1, 1)\n",
    "        #self.conv2A = nn.Conv2d(32, 32, 3, 1, 1)\n",
    "                \n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.conv3A = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        \n",
    "        #self.conv4 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        #self.conv4A = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.conv5A = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        \n",
    "        #self.conv6 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        #self.conv6A = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        self.conv7A = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        #self.conv8 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        #self.conv8A = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=0)\n",
    "        \n",
    "        # after concatenation\n",
    "        self.conv9 = nn.Conv2d(256, 128, 1, 1, 0)\n",
    "        self.conv10 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2-D outputs\n",
    "        \n",
    "    def forward(self,X0,X1,X2):\n",
    "        # ALS patch\n",
    "        x0 = self.pool(F.relu(self.conv1(X0)))     \n",
    "        # x0 = self.pool(F.relu(self.conv2(x0)))\n",
    "        \n",
    "        x0 = self.pool(F.relu(self.conv3(x0)))     \n",
    "        # x0 = self.pool(F.relu(self.conv4(x0)))\n",
    "        \n",
    "        x0 = self.pool(F.relu(self.conv5(x0)))     \n",
    "        #x0 = self.pool(F.relu(self.conv6(x0)))\n",
    "        \n",
    "        x0 = F.relu(self.conv7(x0))     \n",
    "        #x0 = F.relu(self.conv8(x0))\n",
    "        \n",
    "        # DSM2 and ortho               \n",
    "        x1 = torch.cat([X1,X2],1)  # Concatenate \n",
    "        x1 = self.pool(F.relu(self.conv1A(x1)))     \n",
    "        #x1 = self.pool(F.relu(self.conv2A(x1)))\n",
    "        \n",
    "        x1 = self.pool(F.relu(self.conv3A(x1)))     \n",
    "        #x1 = self.pool(F.relu(self.conv4A(x1)))\n",
    "        \n",
    "        x1 = self.pool(F.relu(self.conv5A(x1)))     \n",
    "        #x1 = self.pool(F.relu(self.conv6A(x1)))\n",
    "        \n",
    "        x1 = F.relu(self.conv7A(x1))     \n",
    "        #x1 = F.relu(self.conv8A(x1))\n",
    "                \n",
    "        # Concatenate\n",
    "        x = torch.cat([x0,x1],1)  # size: [64,256,14,14]\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = self.pool(F.relu(self.conv10(x)))\n",
    "        \n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # [SI-HHC-conc-DW] [filter=5&3][3 Conv bocks before] SI-CNN (HH + color!) (UNshared weights)(middle stack fusion)\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        \n",
    "        # Convolution Layer 1      # 1x100x100 input\n",
    "        self.conv1 = nn.Conv2d(1, 6,  kernel_size=5,stride=1,padding=0)  # 3 or 5? \n",
    "        self.conv1A = nn.Conv2d(4, 6, kernel_size=5,stride=1,padding=0)  # 3 or 5?\n",
    "                       \n",
    "        #self.conv2 = nn.Conv2d(32, 32, 3, 1, 1)\n",
    "        #self.conv2A = nn.Conv2d(32, 32, 3, 1, 1)\n",
    "                \n",
    "        self.conv3 = nn.Conv2d(6, 8, 3, 1, 1)\n",
    "        self.conv3A = nn.Conv2d(6, 8, 3, 1, 1)\n",
    "        \n",
    "        #self.conv4 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        #self.conv4A = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(8, 10, 3, 1, 1)\n",
    "        self.conv5A = nn.Conv2d(8, 10, 3, 1, 1)\n",
    "        \n",
    "        #self.conv6 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        #self.conv6A = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        # self.conv7 = nn.Conv2d(10, 12, 3, 1, 1)\n",
    "        # self.conv7A = nn.Conv2d(10, 12, 3, 1, 1)\n",
    "        \n",
    "        #self.conv8 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        #self.conv8A = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=0)\n",
    "        \n",
    "        # after concatenation\n",
    "        self.conv9 = nn.Conv2d(20, 24, 3, 1, 1)\n",
    "        # self.conv10 = nn.Conv2d(30, 32, 3, 1, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(24 * 24 * 24, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2-D outputs\n",
    "        \n",
    "    def forward(self,X0,X1,X2):\n",
    "        # ALS patch\n",
    "        x0 = self.pool(F.relu(self.conv1(X0)))     \n",
    "        # x0 = self.pool(F.relu(self.conv2(x0)))\n",
    "        \n",
    "        x0 = self.pool(F.relu(self.conv3(x0)))     \n",
    "        # x0 = self.pool(F.relu(self.conv4(x0)))\n",
    "        \n",
    "        #x0 = self.pool(F.relu(self.conv5(x0)))     \n",
    "        #x0 = self.pool(F.relu(self.conv6(x0)))\n",
    "        \n",
    "        x0 = F.relu(self.conv5(x0))     \n",
    "        #x0 = F.relu(self.conv8(x0))\n",
    "        \n",
    "        # DSM2 and ortho               \n",
    "        x1 = torch.cat([X1,X2],1)  # Concatenate \n",
    "        x1 = self.pool(F.relu(self.conv1A(x1)))     \n",
    "        #x1 = self.pool(F.relu(self.conv2A(x1)))\n",
    "        \n",
    "        x1 = self.pool(F.relu(self.conv3A(x1)))     \n",
    "        #x1 = self.pool(F.relu(self.conv4A(x1)))\n",
    "        \n",
    "        #x1 = self.pool(F.relu(self.conv5A(x1)))     \n",
    "        #x1 = self.pool(F.relu(self.conv6A(x1)))\n",
    "        \n",
    "        x1 = F.relu(self.conv5A(x1))     \n",
    "        #x1 = F.relu(self.conv8A(x1))\n",
    "                \n",
    "        # Concatenate\n",
    "        x = torch.cat([x0,x1],1)  # size: [64,256,14,14]\n",
    "        x = F.relu(self.conv9(x))\n",
    "        #x = self.pool(F.relu(self.conv9(x)))\n",
    "        \n",
    "        x = x.view(-1, 24 * 24 * 24)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):    # [FF-HH]\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        # which is what we are using.\n",
    "        \n",
    "        # Convolution Layer 1                             # 28 x 28 x 1  (input)\n",
    "        self.conv1 = nn.Conv2d(2, 6, kernel_size=5)      # 24 x 24 x 20  (after 1st convolution)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 22 * 22, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self,X0,X1,X2):\n",
    "        \n",
    "        x = torch.cat([X0,X1],1)  # size of d: [64,2,100,100]\n",
    "        x = self.pool(F.relu(self.conv1(x)))     # 20 x 20 x 30  (after 2nd convolution)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 22 * 22)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):   # [FF-HHC],   Color\n",
    "    def __init__(self):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n",
    "        # which is what we are using.\n",
    "        \n",
    "        # Convolution Layer 1                             # 28 x 28 x 1  (input)\n",
    "        self.conv1 = nn.Conv2d(5, 8, kernel_size=5)      # 24 x 24 x 20  (after 1st convolution)\n",
    "        self.conv2 = nn.Conv2d(8, 10, 5)  # 6->10?\n",
    "        self.conv3 = nn.Conv2d(10, 16, 3, 1, 1)  # 6->10?\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 22 * 22, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self,X0,X1,X2):\n",
    "        \n",
    "        x = torch.cat([X0,X1,X2],1);  # size of d: [64,5,100,100]\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))     # 20 x 20 x 30  (after 2nd convolution)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        x = x.view(-1, 16 * 22 * 22)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4 = CDNet().cuda()\n",
    "net = net4\n",
    "net.train()\n",
    "\n",
    "weights = [1.00, 5.18]   # default: [1.0, 36.94], [1.0, 10.0]\n",
    "class_weights = torch.FloatTensor(weights).cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights,size_average=True)  # BCEWithLogitsLoss()  #   True: loss is averaged over each loss element in batch\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.008, momentum=0.9)  # Good: SGD, 0.01\n",
    "#optimizer = optim.Adamax(net.parameters(), lr=0.003, betas=(0.9, 0.999))  \n",
    "max_train_acc = 0.0;    # initializxe only once, when defining the empty model\n",
    "max_val_acc = 0.0;\n",
    "max_prec = 0.0;\n",
    "\n",
    "train_losses = []\n",
    "train_accuracys = []\n",
    "val_losses = []\n",
    "val_accuracys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The top row and the bottom row of any column is one pair. The 0s and 1s correspond to the column of the image.\n",
    "0 indiciates dissimilar, and 1 indicates similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the learning rate\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)  # 0.003, 0.001,0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.load('Saved_Model_test.pth')\n",
    "net = CDNet().cuda()\n",
    "net.load_state_dict(torch.load('/home/zhangz1/Data/CodeVE/ChangeDetection/Saved_Model_max_val_prec(0.4654).pt'))\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation function.  Input: .   Output: loss per iter and accuracy\n",
    "def Validation(linesVal,NumVal,net):\n",
    "\n",
    "    val_losses = 0.0\n",
    "    val_iterations = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    net.eval()   # Put the network into evaluate mode\n",
    "    TrainFlag = 0\n",
    "    count = 0\n",
    "\n",
    "    Pos_ids = []\n",
    "    Neg_ids = []\n",
    "\n",
    "    for i in range(0,NumVal): # In each iterarion, select at most 64 samples\n",
    "        if i%20000==0:  # Flag\n",
    "            print ('Val-> Iter #: %d/%d' % (i,NumVal))\n",
    "        Pos_ids.append(i)\n",
    "        count = count+1        \n",
    "        if count == 128 or i==NumVal-1:  # In validation mode, Neg_ids and linesNeg don't matter.\n",
    "            batch = batch_loader(Pos_ids,Neg_ids,linesVal,linesVal,TrainFlag);  #  A batch is a 4-element list\n",
    "            # Until now, we get a batch (64D OR less)\n",
    "            # Now start validation:\n",
    "            IM0, IM1, IM2, Lbs = batch\n",
    "            IM0, IM1, IM2, Lbs = Variable(IM0).cuda(), Variable(IM1).cuda(), Variable(IM2).cuda(), Variable(Lbs).cuda()\n",
    "\n",
    "            # forward\n",
    "            outputs = net(IM0,IM1,IM2)\n",
    "            Lbs = torch.tensor(Lbs, dtype=torch.int64)  # convert from float to LongTensor\n",
    "            Lbs = Lbs.view(count)\n",
    "            Lbs = Variable(Lbs).cuda()\n",
    "\n",
    "            # Record the correct predictions for validation data             \n",
    "            loss = criterion(outputs, Lbs)  # average loss\n",
    "            val_losses += loss.data[0] # Accumulate the loss\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_correct += (predicted == Lbs.data).sum()\n",
    "            val_total += Lbs.size(0)\n",
    "            val_iterations += 1\n",
    "            \n",
    "            # Calculate TP, TN, FP, FN\n",
    "            A = predicted + Lbs.data\n",
    "            B = predicted - Lbs.data\n",
    "            C = predicted * Lbs.data\n",
    "            \n",
    "            tp = A.eq(2).sum().item()\n",
    "            fn = B.eq(-1).sum().item()\n",
    "            fp = B.eq(1).sum().item()\n",
    "            tn = Lbs.size(0)-tp-fn-fp\n",
    "            TP = TP+tp\n",
    "            FN = FN+fn\n",
    "            FP = FP+fp\n",
    "            TN = TN+tn\n",
    "            \n",
    "            count = 0  # empty it\n",
    "            Pos_ids = []  # empty it\n",
    "            \n",
    "            # if val_iterations%50==0:\n",
    "            #     print ('Val-> Iter #: %d' % val_iterations)\n",
    "\n",
    "    # Record the val_loss & val_accuracy for all the validation samples\n",
    "    # loss per mini-batch, recorded after every epoch\n",
    "    prec = -1.0\n",
    "    reca = -1.0\n",
    "    if (TP+FP)!=0:\n",
    "        prec = TP/(TP+FP)\n",
    "    if (TP+FN)!=0:\n",
    "        reca = TP/(TP+FN)\n",
    "\n",
    "    return val_losses/val_iterations, 100*val_correct.item()/val_total, val_total, TP,TN,FP,FN, prec, reca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "num_epochs = 20   # default 20\n",
    "batch_size = 128\n",
    "sample_size = 138459\n",
    "num_iters = np.int16(sample_size/batch_size)   # 1081.7\n",
    "print(num_iters)\n",
    "# num_iters = 1  # for debugging\n",
    "\n",
    "Hmin=-16.64   # minimum height in the block\n",
    "Hmax=160.51\n",
    "Hdel=Hmax-Hmin       # Height ranges  \n",
    "\n",
    "fpTrain = open(\"train-merge(138459).txt\", \"r\")\n",
    "linesTrain = fpTrain.readlines()\n",
    "fpTrain.close()\n",
    "\n",
    "# Generate two flag vectors: Pos:[0,20000)   Neg:[0,20000)\n",
    "\n",
    "fpVal = open(\"SampName_Val_(left+right)(107036)(noXY)_refined.txt\", \"r\")    # Validation file\n",
    "linesVal = fpVal.readlines()\n",
    "fpVal.close()\n",
    "NumVal = len(linesVal)\n",
    "\n",
    "iter_loss = 0.0\n",
    "iterations = 0\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "net.train()    # Put the network into training mode\n",
    "TrainFlag = 1\n",
    "\n",
    "linesEmpty = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "start_time = time.time()\n",
    "print(num_epochs)\n",
    "\n",
    "for epoch in range(0,num_epochs):  \n",
    "    if epoch<10:\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)  # 0.003, 0.001,0.0005\n",
    "    if epoch>=10:\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)  # 0.003, 0.001,0.0005\n",
    "\n",
    "    # In each iterarion, select half batches from positive samples, half from neg\n",
    "    Flags = np.random.permutation(sample_size);\n",
    "    \n",
    "    iter_loss = 0.0  # Initialize at the beginning of one epoch\n",
    "    iterations = 0  # Number of iters\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for i in range(0,num_iters):  # num_iters=1081\n",
    "        if i%50==0:  # Initialization per 100 iterations\n",
    "            print ('Epoch %d/%d: Train-> Iter #: %d/%d' % (epoch+1, num_epochs, i,num_iters))\n",
    "        \n",
    "        net.train()    # Put the network into training mode\n",
    "        TrainFlag = 1\n",
    "        \n",
    "        Pos_ids = []\n",
    "        Neg_ids = []\n",
    "        \n",
    "        start = np.int64(i*batch_size)  # batch_size = 128\n",
    "        end   = np.int64((i+1)*batch_size)\n",
    "        \n",
    "        for index in range(start,end):  # Line index\n",
    "            Pos_ids.append(Flags[index])\n",
    "        \n",
    "        batch = batch_loader(Pos_ids,Neg_ids,linesTrain,linesEmpty,TrainFlag);  #  A batch is a 4-element list\n",
    "        \n",
    "        # Now start training with one batch\n",
    "        IM0, IM1, IM2, Lbs = batch\n",
    "        IM0, IM1, IM2, Lbs = Variable(IM0).cuda(), Variable(IM1).cuda(), Variable(IM2).cuda(), Variable(Lbs).cuda()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()    # zero the parameter gradients\n",
    "        outputs = net(IM0,IM1,IM2)\n",
    "        Lbs = torch.tensor(Lbs, dtype=torch.int64)  # convert from float to LongTensor\n",
    "        Lbs =  Lbs.view(128)\n",
    "        Lbs = Variable(Lbs).cuda()\n",
    "        \n",
    "        loss = criterion(outputs, Lbs)\n",
    "        iter_loss += loss.data[0] # Accumulate the loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record the correct predictions for training data \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == Lbs.data).sum()\n",
    "        iterations += 1\n",
    "        train_total += Lbs.size(0)\n",
    "    \n",
    "    # Record the training results, after one epoch\n",
    "    train_losses.append(iter_loss/iterations)  # loss per iteration\n",
    "    train_accuracys.append((100 * train_correct.item() / train_total))\n",
    "\n",
    "    ############################\n",
    "    # Validate - Calculate the Val loss&accuracy per epoch \n",
    "\n",
    "    \n",
    "    if epoch%3 !=0 and epoch!=num_epochs-1:\n",
    "        continue\n",
    "    \n",
    "    val_los,val_accur,val_total,TP,TN,FP,FN, prec,reca = Validation(linesVal,NumVal,net)\n",
    "    \n",
    "    val_losses.append(val_los)  # loss on all the val set\n",
    "    val_accuracys.append(val_accur)\n",
    "    \n",
    "    print ('Tr Loss: %.4f, Tr Acc: %.4f,  Val Loss: %.4f, Val Acc: %.4f'\n",
    "           %(train_losses[-1], train_accuracys[-1], val_losses[-1], val_accuracys[-1]))\n",
    "    print ('TP:%4d,  TN:%4d,  FP:%4d,  FN:%4d,  prec: %.4f, reca: %.4f\\n'\n",
    "               %(TP,TN,FP,FN, prec, reca))\n",
    "\n",
    "    # After 100 iters, check if this is good model, save it\n",
    "    if train_accuracys[-1] > max_train_acc:\n",
    "        #torch.save(net, 'Saved_Model_max_train_acc.pth');\n",
    "        torch.save(net.state_dict(), 'Saved_Model_max_train_acc.pt');\n",
    "        max_train_acc = train_accuracys[-1];\n",
    "        \n",
    "    if val_accuracys[-1] > max_val_acc:\n",
    "        #torch.save(net, 'Saved_Model_max_val_acc.pth');\n",
    "        torch.save(net.state_dict(), 'Saved_Model_max_val_acc.pt');\n",
    "        max_val_acc = val_accuracys[-1];\n",
    "        \n",
    "    if prec > max_prec:\n",
    "        #torch.save(net, 'Saved_Model_max_val_prec.pth');\n",
    "        torch.save(net.state_dict(), 'Saved_Model_max_val_prec.pt');\n",
    "        max_prec = prec;    \n",
    "\n",
    "print('\\nFinished Training and validation.')\n",
    "print('max_train_acc: %.4f, max_val_acc: %.4f, max_val_prec: %.4f\\n'%(max_train_acc,max_val_acc,max_prec));\n",
    "\n",
    "t = (time.time()-start_time)/60.0\n",
    "print(\"--- %s min ---\\n\" % t)\n",
    "\n",
    "print(len(train_losses))\n",
    "print(len(val_losses))\n",
    "print(train_losses)\n",
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_losses))\n",
    "print(len(val_losses))\n",
    "print(train_losses)\n",
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current model & the best model.\n",
    "torch.save(net, 'Saved_Model(T99.9)(V97.0).pth')  # net.state_dict()\n",
    "torch.save(net.state_dict(), 'Saved_Model(T99.9)(V97.0).pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_train_acc,max_val_acc,max_prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = len(train_losses)\n",
    "#cnt = len(train_accuracys)\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 15} # 'weight' : 'bold',\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('axes', linewidth=1)\n",
    "\n",
    "plt.plot(range(0, cnt), train_losses[0:cnt], 'b', label=\"train_loss\",linewidth=2) # plotting t, a separately \n",
    "plt.legend(bbox_to_anchor=(1.2, 0.5), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnt = len(train_losses)\n",
    "cnt = len(train_accuracys)\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 15} # 'weight' : 'bold',\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('axes', linewidth=1)\n",
    "\n",
    "plt.plot(range(0, cnt), train_accuracys[0:cnt], 'b', label=\"train_loss\",linewidth=2) # plotting t, a separately \n",
    "plt.legend(bbox_to_anchor=(1.2, 0.5), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_losses))\n",
    "print(len(train_accuracys))\n",
    "print(len(val_losses))\n",
    "print(len(val_accuracys))\n",
    "\n",
    "# Save the list to txt:  # Validation result: 1-TP, 2-FN, 3-FP, 4-TN\n",
    "with open('Model_train_losses(Siam).txt', 'w') as f:\n",
    "    for item in train_losses:\n",
    "        f.write(\"%f\\n\" % item)\n",
    "f.close()\n",
    "\n",
    "with open('Model_train_accuracys(Siam).txt', 'w') as f:\n",
    "    for item in train_accuracys:\n",
    "        f.write(\"%f\\n\" % item)\n",
    "f.close()\n",
    "\n",
    "with open('Model_val_losses(Siam).txt', 'w') as f:\n",
    "    for item in val_losses:\n",
    "        f.write(\"%f\\n\" % item)\n",
    "f.close()\n",
    "\n",
    "with open('Model_val_accuracys(Siam).txt', 'w') as f:\n",
    "    for item in val_accuracys:\n",
    "        f.write(\"%f\\n\" % item)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "Pos_ids = []  # empty it\n",
    "Neg_ids = []\n",
    "count = 0\n",
    "train_correct = 0\n",
    "outs = []  # Result: 1-TP, 2-FN, 3-FP, 4-TN\n",
    "prec=0\n",
    "reca=0\n",
    "\n",
    "os.chdir('/home/zhangz1/Data/CodeVE/ChangeDetection/Test')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "fpVal = open(\"SampName_All4Blocks_padded(noXY)(135828).txt\", \"r\")    # Validation file\n",
    "linesVal = fpVal.readlines()\n",
    "fpVal.close()\n",
    "NumVal = len(linesVal)\n",
    "print(NumVal)\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(0,NumVal): # In each iterarion, select at most 64 samples\n",
    "    if i%5000==0:\n",
    "        print(i)\n",
    "    Pos_ids.append(i)\n",
    "    count = count+1        \n",
    "    if count == 128 or i== NumVal-1:  # In validation mode, Neg_ids and linesNeg don't matter.\n",
    "        # Neg_ids and linesNeg don't matter.\n",
    "        TrainFlag = 0\n",
    "        \n",
    "        batch = batch_loader(Pos_ids,Neg_ids,linesVal,linesVal,TrainFlag);  #  A batch is a 4-element list\n",
    "        \n",
    "        IM0, IM1, IM2, Lbs = batch\n",
    "        IM0, IM1, IM2, Lbs = Variable(IM0).cuda(), Variable(IM1).cuda(), Variable(IM2).cuda(), Variable(Lbs).cuda()\n",
    "        \n",
    "        # forward\n",
    "        outputs = net(IM0,IM1,IM2)\n",
    "        Lbs = torch.tensor(Lbs, dtype=torch.int64)  # convert from float to LongTensor\n",
    "        Lbs = Lbs.view(count)\n",
    "        Lbs = Variable(Lbs).cuda()\n",
    "        \n",
    "        # Record the correct predictions             \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == Lbs.data).sum()\n",
    "\n",
    "        for j in range(0,count):\n",
    "            if predicted[j].item()==1 and Lbs.data[j].item()==1:\n",
    "                outs.append(1)\n",
    "                TP = TP+1\n",
    "            if predicted[j].item()==0 and Lbs.data[j].item()==1:\n",
    "                outs.append(2)\n",
    "                FN = FN+1\n",
    "            if predicted[j].item()==1 and Lbs.data[j].item()==0:\n",
    "                outs.append(3)\n",
    "                FP = FP+1\n",
    "            if predicted[j].item()==0 and Lbs.data[j].item()==0:\n",
    "                outs.append(4)\n",
    "                TN = TN+1\n",
    "    \n",
    "        Pos_ids = []  # empty it\n",
    "        count = 0\n",
    "\n",
    "print(train_correct)\n",
    "print(len(outs))\n",
    "\n",
    "if (TP+FP)!=0:\n",
    "    prec = TP/(TP+FP)\n",
    "if (TP+FN)!=0:\n",
    "    reca = TP/(TP+FN)\n",
    "F1 = 2*prec*reca/(prec+reca)\n",
    "    \n",
    "print ('TP:%4d,  TN:%4d,  FP:%4d,  FN:%4d,  prec: %.4f, reca: %.4f, F1: %.4f\\n'\n",
    "                   %(TP,TN,FP,FN, prec, reca, F1))\n",
    "\n",
    "t = (time.time()-start_time)/60.0\n",
    "print(\"--- %s min ---\\n\" % t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(outs))\n",
    "\n",
    "# Save the list to txt:  # Validation result: 1-TP, 2-FN, 3-FP, 4-TN\n",
    "with open('Save_testing_results(Siam442)(prec0.4737,reca0.7391,F10.5774).txt', 'w') as f:\n",
    "    for item in outs:\n",
    "        f.write(\"%d\\n\" % item)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "from torchvision.transforms import ToTensor\n",
    "Config.test_txt=\"./data/patches/testing_new_updated3.txt\"   # testing_new  #validation_new_updated3\n",
    "TP=0\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "\n",
    "fp = open(Config.test_txt, \"r\")\n",
    "lines= fp.readlines()\n",
    "\n",
    "file4 = open('save_results.txt', 'w')\n",
    "\n",
    "for i in range(4000,4500):   #  6319  1589   979  800\n",
    "\n",
    "        line=lines[i]\n",
    "        line.strip('\\n')\n",
    "        img_list= line.split()  #img_list has 3 elements\n",
    "        img0 = Image.open(cwd+'/data/'+img_list[0])\n",
    "        img1 = Image.open(cwd+'/data/'+img_list[1])\n",
    "        \n",
    "        img0 = Image.open(cwd+'/data/'+img_list[0])\n",
    "        img1 = Image.open(cwd+'/data/'+img_list[1])\n",
    "\n",
    "        x0 = ToTensor()(img0).unsqueeze(0)  # unsqueeze to add artificial first dimension\n",
    "        x1 = ToTensor()(img1).unsqueeze(0)\n",
    "        output1,output2 = net(Variable(x0).cuda(),Variable(x1).cuda())\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        \n",
    "        pred = euclidean_distance.cpu().data.numpy()[0][0]\n",
    "        \n",
    "        la = img_list[2]\n",
    "        label = np.array(la[0][0]).astype(float)\n",
    "        if (label==1.0) and (pred>0.5):\n",
    "            TP = TP + 1\n",
    "            file4.write(\"TP  %s  %f\\n\" % (img_list[0],pred))\n",
    "            if TP<20:\n",
    "                print('TP:',label,'   ',pred)\n",
    "                print(img_list)\n",
    "                concatenated = torch.cat((x0,x1),0)\n",
    "                imshow(torchvision.utils.make_grid(concatenated))\n",
    "                \n",
    "        elif (label==0.0) and (pred<0.5):\n",
    "            TN = TN + 1\n",
    "            file4.write(\"TN  %s  %f\\n\" % (img_list[0],pred))\n",
    "            if TN<0:\n",
    "                print('TN:',label,'   ',pred)\n",
    "                print(img_list)\n",
    "                concatenated = torch.cat((x0,x1),0)\n",
    "                imshow(torchvision.utils.make_grid(concatenated))\n",
    "        elif (label==1.0) and (pred<= 0.5):  #0.3\n",
    "            FN = FN+1\n",
    "            file4.write(\"FN  %s  %f\\n\" % (img_list[0],pred))\n",
    "            if FN<0:\n",
    "                print('FN:',label,'   ',pred)\n",
    "                print(img_list)\n",
    "                concatenated = torch.cat((x0,x1),0)\n",
    "                imshow(torchvision.utils.make_grid(concatenated))\n",
    "        elif (label==0.0) and (pred>=0.5):   #0.8\n",
    "            FP = FP+1\n",
    "            file4.write(\"FP  %s  %f\\n\" % (img_list[0],pred))\n",
    "            if FP<30:\n",
    "                print('FP:',label,'   ',pred)\n",
    "                print(img_list)\n",
    "                concatenated = torch.cat((x0,x1),0)\n",
    "                imshow(torchvision.utils.make_grid(concatenated))\n",
    "        \n",
    "        if (i%10==0):\n",
    "                print('i=',i)\n",
    "        \n",
    "print('TP=',TP, '  TN=',TN, '  FN=', FN, '  FP=', FP)\n",
    "          \n",
    "# torch.from_numpy(np.array([int(img_list[2])],dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TP=',TP, '  TN=',TN, '  FN=', FN, '  FP=', FP)\n",
    "correctness = TP/(TP+FP)\n",
    "completeness = TP/(TP+FN)\n",
    "all_accu = (TP+TN)/(TP+TN+FN+FP)\n",
    "print('correctness = ',correctness)\n",
    "print('completeness = ',completeness)\n",
    "print('all_accu = ',all_accu)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
